from ding.rl_utils import get_epsilon_greedy_fn

# DQN training loop
eps_cfg = cfg.policy.other.eps
epsilon_greedy = get_epsilon_greedy_fn(eps_cfg.start, eps_cfg.end, eps_cfg.decay, eps_cfg.type)
max_iterations = int(1e8)
for _ in range(max_iterations):
    if evaluator.should_eval(learner.train_iter):
        stop, reward = evaluator.eval(learner.save_checkpoint, learner.train_iter, collector.envstep)
        if stop:
            break
    eps = epsilon_greedy(collector.envstep)
    new_data = collector.collect(train_iter=learner.train_iter, policy_kwargs={'eps': eps})
    replay_buffer.push(new_data, cur_collector_envstep=collector.envstep)
    for i in range(cfg.policy.learn.update_per_collect):
        train_data = replay_buffer.sample(learner.policy.get_attribute('batch_size'), learner.train_iter)
        if train_data is not None:
            learner.train(train_data, collector.envstep)
