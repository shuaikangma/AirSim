[2022-04-17 01:52:18,577][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 14
envstep_count: 229
train_sample_count: 229
avg_envstep_per_episode: 16.357142857142858
avg_sample_per_episode: 16.357142857142858
avg_envstep_per_sec: 12264.000993815562
avg_train_sample_per_sec: 12264.000993815562
avg_episode_per_sec: 749.7642528970212
collect_time: 0.018672535995021458
reward_mean: 16.35714340209961
reward_std: 6.148253440856934
reward_max: 29.0
reward_min: 10.0
total_envstep_count: 336
total_train_sample_count: 336
total_episode_count: 14
total_duration: 0.018672535995021458
[2022-04-17 01:52:18,881][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 11
envstep_count: 253
train_sample_count: 253
avg_envstep_per_episode: 23.0
avg_sample_per_episode: 23.0
avg_envstep_per_sec: 10789.15183583743
avg_train_sample_per_sec: 10789.15183583743
avg_episode_per_sec: 469.0935580798883
collect_time: 0.02344947998225689
reward_mean: 23.0
reward_std: 13.737804412841797
reward_max: 63.0
reward_min: 12.0
total_envstep_count: 608
total_train_sample_count: 608
total_episode_count: 25
total_duration: 0.04212201597727835
[2022-04-17 01:52:19,203][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 11
envstep_count: 263
train_sample_count: 263
avg_envstep_per_episode: 23.90909090909091
avg_sample_per_episode: 23.90909090909091
avg_envstep_per_sec: 10601.01383014524
avg_train_sample_per_sec: 10601.01383014524
avg_episode_per_sec: 443.3884111467591
collect_time: 0.024808947918936612
reward_mean: 23.909090042114258
reward_std: 8.856990814208984
reward_max: 42.0
reward_min: 14.0
total_envstep_count: 880
total_train_sample_count: 880
total_episode_count: 36
total_duration: 0.06693096389621496
[2022-04-17 01:52:19,509][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 12
envstep_count: 304
train_sample_count: 304
avg_envstep_per_episode: 25.333333333333332
avg_sample_per_episode: 25.333333333333332
avg_envstep_per_sec: 11907.832100040408
avg_train_sample_per_sec: 11907.832100040408
avg_episode_per_sec: 470.04600394896346
collect_time: 0.02552941605541855
reward_mean: 25.33333396911621
reward_std: 15.616941452026367
reward_max: 60.0
reward_min: 10.0
total_envstep_count: 1152
total_train_sample_count: 1152
total_episode_count: 48
total_duration: 0.0924603799516335
[2022-04-17 01:52:19,881][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 9
envstep_count: 224
train_sample_count: 224
avg_envstep_per_episode: 24.88888888888889
avg_sample_per_episode: 24.88888888888889
avg_envstep_per_sec: 10263.639910906384
avg_train_sample_per_sec: 10263.639910906384
avg_episode_per_sec: 412.3783892774886
collect_time: 0.0218246160177514
reward_mean: 24.88888931274414
reward_std: 8.569252967834473
reward_max: 39.0
reward_min: 12.0
total_envstep_count: 1424
total_train_sample_count: 1424
total_episode_count: 57
total_duration: 0.1142849959693849
[2022-04-17 01:52:46,735][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 14
envstep_count: 229
train_sample_count: 229
avg_envstep_per_episode: 16.357142857142858
avg_sample_per_episode: 16.357142857142858
avg_envstep_per_sec: 7700.922807156189
avg_train_sample_per_sec: 7700.922807156189
avg_episode_per_sec: 470.79877423662293
collect_time: 0.02973669594340026
reward_mean: 16.35714340209961
reward_std: 6.148253440856934
reward_max: 29.0
reward_min: 10.0
total_envstep_count: 336
total_train_sample_count: 336
total_episode_count: 14
total_duration: 0.02973669594340026
[2022-04-17 01:52:47,145][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 11
envstep_count: 253
train_sample_count: 253
avg_envstep_per_episode: 23.0
avg_sample_per_episode: 23.0
avg_envstep_per_sec: 7871.655060917204
avg_train_sample_per_sec: 7871.655060917204
avg_episode_per_sec: 342.2458722137915
collect_time: 0.032140635996125634
reward_mean: 23.0
reward_std: 13.737804412841797
reward_max: 63.0
reward_min: 12.0
total_envstep_count: 608
total_train_sample_count: 608
total_episode_count: 25
total_duration: 0.061877331939525895
[2022-04-17 01:52:47,488][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 11
envstep_count: 263
train_sample_count: 263
avg_envstep_per_episode: 23.90909090909091
avg_sample_per_episode: 23.90909090909091
avg_envstep_per_sec: 9818.268675655483
avg_train_sample_per_sec: 9818.268675655483
avg_episode_per_sec: 410.65002065479206
collect_time: 0.02678680006507784
reward_mean: 23.909090042114258
reward_std: 8.856990814208984
reward_max: 42.0
reward_min: 14.0
total_envstep_count: 880
total_train_sample_count: 880
total_episode_count: 36
total_duration: 0.08866413200460374
[2022-04-17 01:52:47,781][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 12
envstep_count: 304
train_sample_count: 304
avg_envstep_per_episode: 25.333333333333332
avg_sample_per_episode: 25.333333333333332
avg_envstep_per_sec: 11498.73621531265
avg_train_sample_per_sec: 11498.73621531265
avg_episode_per_sec: 453.89748218339406
collect_time: 0.026437687960453336
reward_mean: 25.33333396911621
reward_std: 15.616941452026367
reward_max: 60.0
reward_min: 10.0
total_envstep_count: 1152
total_train_sample_count: 1152
total_episode_count: 48
total_duration: 0.11510181996505708
[2022-04-17 01:52:48,098][sample_serial_collector.py][line: 346][    INFO] collect end:
episode_count: 9
envstep_count: 224
train_sample_count: 224
avg_envstep_per_episode: 24.88888888888889
avg_sample_per_episode: 24.88888888888889
avg_envstep_per_sec: 11830.262002304076
avg_train_sample_per_sec: 11830.262002304076
avg_episode_per_sec: 475.32302687828883
collect_time: 0.018934491895139217
reward_mean: 24.88888931274414
reward_std: 8.569252967834473
reward_max: 39.0
reward_min: 12.0
total_envstep_count: 1424
total_train_sample_count: 1424
total_episode_count: 57
total_duration: 0.1340363118601963
